{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWwFjGn0yt4tcaUS1/n/+Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Embedding, Dropout\n","from tensorflow.keras.optimizers import Adam\n"],"metadata":{"id":"fxs95MMZU_5V","executionInfo":{"status":"ok","timestamp":1732035392657,"user_tz":-420,"elapsed":7933,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Data dummy: mengganti dengan dataset nyata dalam aplikasi nyata\n","input_texts = [\"how are you?\"]\n","target_texts = [\"comment vas-tu?\"]\n","\n","# Membuat tokenizer\n","input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","target_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","\n","# Fit tokenizer pada data\n","input_tokenizer.fit_on_texts(input_texts)\n","target_tokenizer.fit_on_texts(target_texts)\n","\n","# Konversi teks menjadi urutan angka\n","input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n","target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n","\n","# Tambahkan token khusus <start> dan <end> ke target_texts\n","target_texts = [\"<start> \" + text + \" <end>\" for text in target_texts]\n","\n","# Tokenizer tetap sama\n","target_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","target_tokenizer.fit_on_texts(target_texts)\n","\n","# Konversi teks menjadi urutan angka\n","target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n","\n","# Padding\n","max_input_len = max(len(seq) for seq in input_sequences)\n","max_target_len = max(len(seq) for seq in target_sequences)\n","\n","input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n","target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n","\n","# Split input dan output untuk decoder\n","decoder_input_sequences = target_sequences[:, :-1]\n","decoder_target_sequences = target_sequences[:, 1:]\n","\n","# Hyperparameters\n","vocab_size_input = len(input_tokenizer.word_index) + 1\n","vocab_size_target = len(target_tokenizer.word_index) + 1\n","embedding_dim = 256\n","hidden_dim = 512\n"],"metadata":{"id":"4uuXxz7OWSOy","executionInfo":{"status":"ok","timestamp":1732035554395,"user_tz":-420,"elapsed":750,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Encoder\n","encoder_inputs = Input(shape=(None,), name=\"encoder_inputs\")\n","encoder_embedding = Embedding(vocab_size_input, embedding_dim, name=\"encoder_embedding\")(encoder_inputs)\n","encoder_gru = GRU(hidden_dim, return_state=True, name=\"encoder_gru\")  # Replace GRU with LSTM if needed\n","encoder_outputs, encoder_state = encoder_gru(encoder_embedding)\n","\n","# Decoder\n","decoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\n","decoder_embedding = Embedding(vocab_size_target, embedding_dim, name=\"decoder_embedding\")(decoder_inputs)\n","decoder_gru = GRU(hidden_dim, return_sequences=True, return_state=True, name=\"decoder_gru\")\n","decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=encoder_state)\n","decoder_dense = Dense(vocab_size_target, activation=\"softmax\", name=\"decoder_dense\")\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer=Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"1iWtugsRWT3o","executionInfo":{"status":"ok","timestamp":1732035561115,"user_tz":-420,"elapsed":1399,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}},"outputId":"494ced03-d42f-4ee1-97d7-d5a46f3bbc7e"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ encoder_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,280\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,792\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ encoder_gru (\u001b[38;5;33mGRU\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m1,182,720\u001b[0m │ encoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_gru (\u001b[38;5;33mGRU\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │      \u001b[38;5;34m1,182,720\u001b[0m │ decoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]           │                │ encoder_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │          \u001b[38;5;34m3,591\u001b[0m │ decoder_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ encoder_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ encoder_gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │ encoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │ decoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]           │                │ encoder_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │ decoder_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,372,103\u001b[0m (9.05 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,372,103</span> (9.05 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,372,103\u001b[0m (9.05 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,372,103</span> (9.05 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# Train the model tanpa validation_split\n","history = model.fit(\n","    [input_sequences, decoder_input_sequences],\n","    decoder_target_sequences,\n","    batch_size=32,\n","    epochs=10,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mR7nuIYzXlkz","executionInfo":{"status":"ok","timestamp":1732035640448,"user_tz":-420,"elapsed":5816,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}},"outputId":"d450a331-0c52-4eb7-d6cf-631c72fd6b91"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.2000 - loss: 1.9430\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.8632\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.7811\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.6895\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 1.5818\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 1.4504\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 1.2875\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.0880\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.8593\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.6356\n"]}]},{"cell_type":"code","source":["# Encoder model for inference\n","encoder_model = Model(encoder_inputs, encoder_state)\n","\n","# Decoder model for inference\n","decoder_state_input = Input(shape=(hidden_dim,))\n","decoder_outputs, decoder_state = decoder_gru(decoder_embedding, initial_state=decoder_state_input)\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model([decoder_inputs, decoder_state_input], [decoder_outputs, decoder_state])\n","\n","# Function to decode sequence\n","def decode_sequence(input_seq):\n","    state_value = encoder_model.predict(input_seq)\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = start_token\n","\n","    decoded_sentence = \"\"\n","    while True:\n","        output_tokens, state_value = decoder_model.predict([target_seq, state_value])\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = target_tokenizer.index_word[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_word\n","\n","        if sampled_word == \"<end>\" or len(decoded_sentence.split()) > max_target_len:\n","            break\n","\n","        target_seq[0, 0] = sampled_token_index\n","\n","    return decoded_sentence\n"],"metadata":{"id":"voFGMQ1KWWy-","executionInfo":{"status":"ok","timestamp":1732035646152,"user_tz":-420,"elapsed":336,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Tentukan ID untuk token <start> dan <end>\n","START_TOKEN_ID = 1\n","END_TOKEN_ID = 2\n","\n","# Tambahkan token ID ini secara manual ke urutan target\n","target_sequences = [[START_TOKEN_ID] + seq + [END_TOKEN_ID] for seq in target_sequences]\n","\n","# Lakukan padding ulang setelah menambahkan token\n","target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n","\n","# Pisahkan decoder input dan target\n","decoder_input_sequences = [seq[:-1] for seq in target_sequences]\n","decoder_target_sequences = [seq[1:] for seq in target_sequences]\n","\n","decoder_input_sequences = np.array(decoder_input_sequences)\n","decoder_target_sequences = np.array(decoder_target_sequences)\n"],"metadata":{"id":"7aXiedVxZkSn","executionInfo":{"status":"ok","timestamp":1732036154472,"user_tz":-420,"elapsed":336,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def decode_sequence(input_seq):\n","    state_value = encoder_model.predict(input_seq)\n","    target_seq = np.zeros((1, 1))\n","    target_seq[0, 0] = START_TOKEN_ID  # Gunakan ID tetap untuk token awal\n","\n","    decoded_sentence = \"\"\n","    while True:\n","        output_tokens, state_value = decoder_model.predict([target_seq, state_value])\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","\n","        # Cegah error jika ID tidak ditemukan\n","        sampled_word = target_tokenizer.index_word.get(sampled_token_index, \"<UNK>\")\n","        decoded_sentence += \" \" + sampled_word\n","\n","        if sampled_token_index == END_TOKEN_ID or len(decoded_sentence.split()) > max_target_len:\n","            break\n","\n","        target_seq[0, 0] = sampled_token_index\n","\n","    return decoded_sentence\n"],"metadata":{"id":"crPDtZEWZmt8","executionInfo":{"status":"ok","timestamp":1732036163755,"user_tz":-420,"elapsed":322,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Test decoding\n","test_input = input_sequences[0:1]\n","decoded_output = decode_sequence(test_input)\n","print(\"Decoded output:\", decoded_output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5sanSxGZo4S","executionInfo":{"status":"ok","timestamp":1732036172941,"user_tz":-420,"elapsed":422,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}},"outputId":"2030054f-e36f-4a91-eb74-f131f1dd1a83"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n","Decoded output:  end\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","reference = [\"<start> ravi de vous rencontrer <end>\".split()]\n","candidate = decoded_output.split()\n","bleu_score = sentence_bleu([reference], candidate)\n","print(\"BLEU Score:\", bleu_score)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":876},"id":"4Ij5FDXLetJG","executionInfo":{"status":"error","timestamp":1732037500918,"user_tz":-420,"elapsed":368,"user":{"displayName":"065_MELIZA WULANDARI","userId":"15457601190170839248"}},"outputId":"c63036ad-8ed7-4a77-90a5-f0fc5bc006db"},"execution_count":30,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unhashable type: 'list'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-cf0120ac290f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<start> ravi de vous rencontrer <end>\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLEU Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36msentence_bleu\u001b[0;34m(references, hypothesis, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     return corpus_bleu(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_reweigh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# denominator for the corpus-level modified precision.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_weight_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0mp_numerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mp_denominators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         reference_counts = (\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         )\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m         '''\n\u001b[1;32m    576\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"]}]},{"cell_type":"markdown","source":["# Analisi\n","**1. Bagaimana cara memodifikasi laju pembelajaran (learning rate) dan ukuran batch untuk  meningkatkan kinerja model sequence-to-sequence?**\n","\n","pada kode diatas laju pembelajaran (learning rate) ditentukan di bagian Adam(learning_rate=0.001). Ukuran batch didefinisikan sebagai (batch_size=32)\n","\n","**2. Jalankan eksperimen tanpa menggunakan regularisasi dropout. Perubahan apa yang Anda  amati dalam kinerja model? Mengapa hal ini bisa terjadi?**\n","\n","Tidak ada regularisasi dropout yang diterapkan dalam model ini. Tanpa dropout, model Anda menunjukkan konvergensi cepat (dari accuracy: 0.2 ke accuracy: 1.0 dalam beberapa epoch), tetapi ini bisa menyebabkan overfitting pada dataset besar. Dropout membantu generalisasi dengan mencegah jaringan terlalu bergantung pada subset neuron tertentu. Tanpa dropout, model lebih cenderung menghafal data pelatihan daripada mempelajari pola umum.\n","\n","**3. Jika encoder menggunakan lapisan bidirectional tetapi decoder tidak, bagaimana Anda dapat  menyesuaikan decoder untuk menangani perbedaan arsitektur ini? **\n","\n","Pada encoder, ketika menggunakan lapisan bidirectional (seperti Bidirectional GRU), output dari encoder terdiri dari dua state, yaitu state maju (forward) dan mundur (backward), yang perlu digabungkan menjadi satu vektor. Oleh karena itu, ukuran state encoder menjadi dua kali lipat dibandingkan dengan keadaan unidirectional. Untuk menyesuaikan hal ini, pada decoder, Anda harus menggandakan ukuran dimensi tersembunyi (hidden dimension) GRU pada decoder, sehingga dapat menangani ukuran state yang lebih besar. Dengan demikian, decoder GRU perlu disesuaikan dengan ukuran dua kali lipat dari dimensi tersembunyi pada encoder, yaitu hidden_dim * 2, untuk memastikan kompatibilitas antara encoder dan decoder dalam model seq2seq.\n","\n","\n","**4. Pada proses pelatihan, ganti teacher forcing dengan pendekatan scheduled sampling. Apa  dampaknya terhadap konvergensi dan kinerja model?**\n","\n","- Teacher forcing: Memberikan token target aktual sebagai input selama pelatihan, mempercepat konvergensi.\n","- Scheduled sampling: Mencampur penggunaan token target dan prediksi model secara bertahap, mengurangi ketergantungan pada token target.\n","Dampak nya yaitu Konvergensi lebih lambat dibandingkan teacher forcing penuh. Model menjadi lebih robust selama inferensi, karena terbiasa menangani kesalahan prediksi sebelumnya. Scheduled sampling membantu generalisasi tetapi membutuhkan waktu pelatihan lebih lama.\n","\n","\n","**5. Cobalah mengganti LSTM dengan GRU dalam model sequence-to-sequence. Perbedaan apa  yang Anda perhatikan dalam hasilnya?**\n","\n","pada model diatas sudah mengganti GRu dengan LSTM dimana kedua metode memiliki perbedaan yaitu GRU: Lebih cepat dan ringan secara komputasi karena hanya memiliki dua gate (update dan reset).\n","LSTM: Lebih kompleks, dapat menangkap dependensi jangka panjang lebih baik dengan tiga gate (input, forget, dan output). Untuk dataset kecil, GRU cenderung lebih efisien, sementara LSTM lebih baik untuk dataset dengan dependensi panjang.\n","\n","**6. Bagaimana skor evaluasi BLEU dari data di atas?**\n","\n","Jika model Anda menghasilkan terjemahan yang sempurna (contoh: \"ravi de vous rencontrer <end>\"), skor BLEU akan mendekati 1.0. Skor lebih rendah menunjukkan kesalahan dalam prediksi token."],"metadata":{"id":"pKND58n2dPKD"}},{"cell_type":"code","source":[],"metadata":{"id":"cNv5FcZ4cBIs"},"execution_count":null,"outputs":[]}]}